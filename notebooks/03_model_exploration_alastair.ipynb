{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# LLM Simplification Exploration\n",
                "\n",
                "This notebook tests the basic connection to Groq and runs a simple text simplification task."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Setup and Imports\n",
                "import os\n",
                "from dotenv import load_dotenv\n",
                "from groq import Groq\n",
                "\n",
                "# Load environment variables from .env file\n",
                "load_dotenv()\n",
                "\n",
                "api_key = os.getenv(\"GROQ_API_KEY\")\n",
                "\n",
                "if not api_key:\n",
                "    print(\"‚ùå ERROR: GROQ_API_KEY not found in .env\")\n",
                "else:\n",
                "    print(\"‚úÖ GROQ_API_KEY found.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Initialize Client\n",
                "if api_key:\n",
                "    client = Groq(api_key=api_key)\n",
                "    print(\"Client initialized.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Load Sample Data\n",
                "sample_path = '../data/samples/sample_en.txt'\n",
                "\n",
                "if os.path.exists(sample_path):\n",
                "    with open(sample_path, 'r') as f:\n",
                "        original_text = f.read().strip()\n",
                "    print(f\"Loaded text ({len(original_text)} chars):\\n\")\n",
                "    print(\"---\")\n",
                "    print(original_text)\n",
                "    print(\"---\")\n",
                "else:\n",
                "    print(f\"‚ùå File not found: {sample_path}\")\n",
                "    original_text = \"The quick brown fox jumps over the lazy dog.\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Run Simplification\n",
                "simplified_text = \"\"\n",
                "\n",
                "if api_key and original_text:\n",
                "    try:\n",
                "        completion = client.chat.completions.create(\n",
                "            model=\"llama-3.1-8b-instant\",\n",
                "            messages=[\n",
                "                {\n",
                "                    \"role\": \"system\",\n",
                "                    \"content\": \"Simplify the following text for a general audience. Make it easier to read and understand.\"\n",
                "                },\n",
                "                {\n",
                "                    \"role\": \"user\",\n",
                "                    \"content\": original_text\n",
                "                }\n",
                "            ],\n",
                "            temperature=0.5,\n",
                "            max_tokens=1024,\n",
                "            top_p=1,\n",
                "            stream=False,\n",
                "            stop=None,\n",
                "        )\n",
                "        \n",
                "        simplified_text = completion.choices[0].message.content\n",
                "        print(\"\\n‚ú® Simplified Text:\\n\")\n",
                "        print(\"---\")\n",
                "        print(simplified_text)\n",
                "        print(\"---\")\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Error calling LLM: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Evaluate Simplification\n",
                "def evaluate_text(text):\n",
                "    if not text: return \"No text to evaluate.\"\n",
                "    \n",
                "    try:\n",
                "        prompt = f\"\"\"\n",
                "        Evaluate the following text for: \n",
                "        1. Simplicity (1-10)\n",
                "        2. Readability (1-10)\n",
                "        3. Universal Understanding (1-10)\n",
                "        \n",
                "        Text: \"{text}\"\n",
                "        \n",
                "        Provide the scores and a brief 1-sentence explanation for each.\n",
                "        \"\"\"\n",
                "        \n",
                "        completion = client.chat.completions.create(\n",
                "            model=\"llama-3.1-8b-instant\",\n",
                "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                "            temperature=0.1\n",
                "        )\n",
                "        return completion.choices[0].message.content\n",
                "        \n",
                "    except Exception as e:\n",
                "        return f\"Error evaluating: {e}\"\n",
                "\n",
                "if simplified_text:\n",
                "    print(\"\\nüìä Evaluation Results:\\n\")\n",
                "    print(evaluate_text(simplified_text))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 6. Hugging Face Data Integration\n",
                "\n",
                "Now testing with real data from the `wiki_lingua` dataset (a standard for simplification)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from datasets import load_dataset\n",
                "import pandas as pd\n",
                "\n",
                "try:\n",
                "    # Load a small slice of the dataset (first 3 examples)\n",
                "    print(\"‚è≥ Loading dataset slice (wiki_lingua)...\")\n",
                "    dataset = load_dataset(\"wiki_lingua\", \"english\", split=\"train[:3]\", trust_remote_code=True)\n",
                "    \n",
                "    print(f\"‚úÖ Loaded {len(dataset)} examples.\")\n",
                "except Exception as e:\n",
                "    print(f\"‚ùå Error loading dataset: {e}\")\n",
                "    dataset = []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run simplification loop\n",
                "if hasattr(dataset, '__iter__') and len(dataset) > 0:\n",
                "    for i, item in enumerate(dataset):\n",
                "        # Extract text (WikiLingua structure is specific, handling basic case)\n",
                "        try:\n",
                "             # 'article' is usually the source dict, 'document' is the text list\n",
                "            input_text = item['article']['document'][0] \n",
                "        except:\n",
                "            input_text = str(item) # Fallback\n",
                "\n",
                "        print(f\"\\n--- Example {i+1} ---\")\n",
                "        print(f\"üìù Input (snippet): {input_text[:150]}...\")\n",
                "        \n",
                "        # Simplify\n",
                "        if api_key:\n",
                "            try:\n",
                "                completion = client.chat.completions.create(\n",
                "                    model=\"llama-3.1-8b-instant\",\n",
                "                    messages=[\n",
                "                        {\"role\": \"system\", \"content\": \"Simplify this text.\"}, \n",
                "                        {\"role\": \"user\", \"content\": input_text}\n",
                "                    ],\n",
                "                    temperature=0.5\n",
                "                )\n",
                "                result = completion.choices[0].message.content\n",
                "                print(f\"‚ú® Simplified: {result[:150]}... (check full output in var)\")\n",
                "                \n",
                "                # Optional: Evaluate (commented out to save tokens/time if needed)\n",
                "                # score = evaluate_text(result)\n",
                "                # print(f\"üìä {score.splitlines()[0]}...\")\n",
                "                \n",
                "            except Exception as e:\n",
                "                print(f\"Error: {e}\")\n",
                "else:\n",
                "    print(\"Skipping loop (no dataset loaded).\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}